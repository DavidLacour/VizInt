Using device: cuda

=== Checking for existing models (mode: all) ===

=== Training Main Classification Model ===
Using device: cuda
Phase 1: Finding an initial working batch size...
Starting batch size 128 fits in memory!
Phase 2: Refining batch size around 128...
Testing batch size: 144...
Testing batch size: 160...
Testing batch size: 152...
Testing batch size: 148...
Testing batch size: 146...
Testing batch size: 145...
Found optimal batch size: 144
Using safe batch size: 139
Training set size: 100000
Validation set size: 10000
Epoch 1/50: 100%|██████████████████████████████████████████████████████████████████| 720/720 [03:50<00:00,  3.13it/s, loss=4.24]
Epoch 1/50 - Train Loss: 4.7902, Train Acc: 0.0599, Val Loss: 4.0844, Val Acc: 0.1342
Saved best model with validation accuracy: 0.1342
Epoch 2/50: 100%|██████████████████████████████████████████████████████████████████| 720/720 [03:53<00:00,  3.08it/s, loss=3.04]
Epoch 2/50 - Train Loss: 3.6459, Train Acc: 0.1998, Val Loss: 3.3961, Val Acc: 0.2381
Saved best model with validation accuracy: 0.2381
Epoch 3/50: 100%|██████████████████████████████████████████████████████████████████| 720/720 [03:55<00:00,  3.05it/s, loss=3.05]
Epoch 3/50 - Train Loss: 3.0402, Train Acc: 0.3023, Val Loss: 3.0396, Val Acc: 0.3068
Saved best model with validation accuracy: 0.3068
Epoch 4/50:  22%|██████████████▊                                                   | 162/720 [00:58<03:23,  2.75it/s, loss=2.54]
Traceback (most recent call last):
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/main_baselines_3fc.py", line 570, in <module>
    main()
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/main_baselines_3fc.py", line 436, in main
    main_model = train_main_model(args.dataset)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/new_new.py", line 824, in train_main_model
    loss.backward()
  File "/home/david-lacour/.pyenv/versions/myenv/lib/python3.12/site-packages/torch/_tensor.py", line 648, in backward
    torch.autograd.backward(
  File "/home/david-lacour/.pyenv/versions/myenv/lib/python3.12/site-packages/torch/autograd/__init__.py", line 353, in backward
    _engine_run_backward(
  File "/home/david-lacour/.pyenv/versions/myenv/lib/python3.12/site-packages/torch/autograd/graph.py", line 824, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
