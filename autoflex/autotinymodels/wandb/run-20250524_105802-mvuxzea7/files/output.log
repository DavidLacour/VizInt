Using device: cuda

=== Checking for existing models (mode: all) ===

=== Training Main Classification Model ===
Using device: cuda
Phase 1: Finding an initial working batch size...
Starting batch size 128 fits in memory!
Phase 2: Refining batch size around 128...
Testing batch size: 144...
Testing batch size: 160...
Testing batch size: 152...
Testing batch size: 148...
Testing batch size: 146...
Testing batch size: 145...
Found optimal batch size: 144
Using safe batch size: 139
Training set size: 100000
Validation set size: 10000
Epoch 1/50:   2%|â–ˆ                                                                  | 11/720 [00:04<04:43,  2.50it/s, loss=5.99]
Traceback (most recent call last):
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/main_baselines_3fc.py", line 570, in <module>
    main()
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/main_baselines_3fc.py", line 436, in main
    main_model = train_main_model(args.dataset)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/new_new.py", line 830, in train_main_model
    train_loss += loss.item()
                  ^^^^^^^^^^^
KeyboardInterrupt
