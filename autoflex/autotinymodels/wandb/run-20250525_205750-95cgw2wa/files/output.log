Using device: cuda

=== Loading Models ===
Loading main model from ../../newModels/bestmodel_main/best_model.pt
Loading main model from ../../newModels/bestmodel_robust/best_model.pt
Loading healer model from ../../newModels/bestmodel_healer/best_model.pt

=== Evaluating Models ===
Evaluating Main Model: 100%|██████████| 313/313 [00:08<00:00, 38.87it/s]
Main Model: 34.88%
Evaluating Robust Main Model: 100%|██████████| 313/313 [00:07<00:00, 40.48it/s]
Robust Main Model: 42.64%
Traceback (most recent call last):
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/evaluate_all_models.py", line 272, in <module>
    main()
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/evaluate_all_models.py", line 256, in main
    results = evaluate_all_combinations(model_dir, dataset_path, device)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/evaluate_all_models.py", line 176, in evaluate_all_combinations
    blended_model = BlendedTTT(main_model, healer_model)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/blended_ttt_model.py", line 58, in __init__
    self.patch_embed = PatchEmbed(
                       ^^^^^^^^^^^
  File "/home/david-lacour/Documents/transformerVision/githubs/VizInt/autoflex/autotinymodels/vit_implementation.py", line 33, in __init__
    self.grid_size = (img_size[0] // patch_size[0], img_size[1] // patch_size[1])
                      ~~~~~~~~^^^
TypeError: 'VisionTransformer' object is not subscriptable
